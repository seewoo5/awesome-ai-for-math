---
title: Transformer
layout: default
---

# Transformer papers

| Title | Subject(s) | Venue & Year | Links & Resources |
| :--- | :--- | :--- | :--- |
| **[Can Transformers Do Enumerative Geometry?](https://proceedings.iclr.cc/paper_files/paper/2025/file/aee2f03ecb2b2c1ea55a43946b651cfd-Paper-Conference.pdf)** | [Algebraic Geometry](algebraic-geometry.md), [Interpretability](interpretability.md), [Transformer](transformer.md) | ICLR 2025 | [Code](https://github.com/Baran-phys/DynamicFormer) |
| **[Deep Learning for Symbolic Mathematics](https://openreview.net/forum?id=S1eZYeHFDS)** | [Differential Equations](differential-equations.md), [Symbolic Computation](symbolic-computation.md), [Transformer](transformer.md) | ICLR 2020 | [Code](https://github.com/facebookresearch/SymbolicMathematics) |
| **[Flow-based Extremal Mathematical Structure Discovery](https://www.arxiv.org/abs/2601.18005)** | [Combinatorics](combinatorics.md), [Transformer](transformer.md), [Discrete Geometry](discrete-geometry.md), [RL](rl.md) | arXiv 2026 | [Code](https://github.com/berczig/FlowBoost) |
| **[From Black Box to Bijection: Interpreting Machine Learning to Build a Zeta Map Algorithm](https://www.arxiv.org/abs/2511.12421)** | [Combinatorics](combinatorics.md), [Transformer](transformer.md) | arXiv 2025 |  |
| **[Geometric Generality of Transformer-Based Gröbner Basis Computation](https://arxiv.org/abs/2504.12465)** | [Algebraic Geometry](algebraic-geometry.md), [Transformer](transformer.md) | arXiv 2025 |  |
| **[Global Lyapunov functions: a long-standing open problem in mathematics, with symbolic transformers](https://proceedings.neurips.cc/paper_files/paper/2024/file/aa280e73c4e23e765fde232571116d3b-Paper-Conference.pdf)** | [Differential Equations](differential-equations.md), [Transformer](transformer.md) | NeurIPS 2024 | [Code](https://github.com/facebookresearch/Lyapunov) |
| **[Int2Int: a framework for mathematics with transformers](https://arxiv.org/abs/2502.17513)** | [Number Theory](number-theory.md), [Transformer](transformer.md) | arXiv 2025 | [Code](https://github.com/f-charton/Int2Int) |
| **[Interpretable Machine Learning for Kronecker Coefficients](https://arxiv.org/abs/2502.11774)** | [Representation Theory](representation-theory.md), [Neural Network](neural-network.md), [Symbolic Computation](symbolic-computation.md), [PCA](pca.md), [Transformer](transformer.md) | arXiv 2025 |  |
| **[Learning Euler factors of elliptic curves](https://arxiv.org/abs/2502.10357)** | [Number Theory](number-theory.md), [Transformer](transformer.md) | arXiv 2025 |  |
| **[Learning the Inverse Ryu--Takayanagi Formula with Transformers](https://arxiv.org/abs/2511.06387)** | [Mathematical Physics](mathematical-physics.md), [Transformer](transformer.md) | arXiv 2025 | [Code](https://github.com/power817/HEE_3D) |
| **[Learning to compute Gröbner Basis](https://proceedings.neurips.cc/paper_files/paper/2024/hash/3a1de90699eec7d7f42c91d81f94af16-Abstract-Conference.html)** | [Algebraic Geometry](algebraic-geometry.md), [Transformer](transformer.md) | NeurIPS 2024 | [Code](https://github.com/HiroshiKERA/transformer-groebner) |
| **[Learning Topological Invariance](https://arxiv.org/abs/2504.12390)** | [Knot Theory](knot-theory.md), [Neural Network](neural-network.md), [Transformer](transformer.md) | arXiv 2025 |  |
| **[Linear algebra with transformers](https://openreview.net/forum?id=Hp4g7FAXXG)** | [Linear Algebra](linear-algebra.md), [Symbolic Computation](symbolic-computation.md), [Transformer](transformer.md) | TMLR 2022 | [Code](https://github.com/facebookresearch/LAWT) |
| **[Machine learning for modular multiplication](https://arxiv.org/abs/2402.19254)** | [Number Theory](number-theory.md), [Transformer](transformer.md) | arXiv 2024 | [Code](https://github.com/meghabyte/mod-math/) |
| **[PatternBoost: Constructions in Mathematics with a Little Help from AI](https://arxiv.org/abs/2411.00566)** | [Discrete Geometry](discrete-geometry.md), [Combinatorics](combinatorics.md), [Transformer](transformer.md), [RL](rl.md) | arXiv 2024 | [Code](https://github.com/zawagner22/transformers_math_experiments) |
| **[Studying number theory with deep learning: a case study with the Möbius and squarefree indicator functions](https://arxiv.org/abs/2502.10335)** | [Number Theory](number-theory.md), [Transformer](transformer.md) | arXiv 2025 | [Code](https://github.com/davidlowryduda/mobius_case_study) |
| **[What makes math problems hard for reinforcement learning: a case study](https://arxiv.org/abs/2408.15332)** | [Group Theory](group-theory.md), [RL](rl.md), [Transformer](transformer.md) | arXiv 2024 | [Code](https://github.com/shehper/AC-Solver) |