---
title: Transformer
layout: default
---

# Transformer papers

| Title | Subject(s) | Venue & Year | Links & Resources |
| :--- | :--- | :--- | :--- |
| **[Can Transformers Do Enumerative Geometry?](https://proceedings.iclr.cc/paper_files/paper/2025/file/aee2f03ecb2b2c1ea55a43946b651cfd-Paper-Conference.pdf)** | [Algebraic Geometry](algebraic-geometry.md), [Interpretability](interpretability.md), [Transformer](transformer.md) | ICLR 2025 | [Code](https://github.com/Baran-phys/DynamicFormer) |
| **[Geometric Generality of Transformer-Based Gröbner Basis Computation](https://arxiv.org/abs/2504.12465)** | [Algebraic Geometry](./subjects/algebraic-geometry.md), [Transformer](./subjects/transformer.md) | arXiv 2025 |  |
| **[Global Lyapunov functions: a long-standing open problem in mathematics, with symbolic transformers](https://proceedings.neurips.cc/paper_files/paper/2024/file/aa280e73c4e23e765fde232571116d3b-Paper-Conference.pdf)** | [Analysis](analysis.md), [Transformer](transformer.md) | NeurIPS 2024 | [Code](https://github.com/facebookresearch/Lyapunov) |
| **[Int2Int: a framework for mathematics with transformers](https://arxiv.org/abs/2502.17513)** | [Number Theory](number-theory.md), [Transformer](transformer.md) | arXiv 2025 | [Code](https://github.com/f-charton/Int2Int) |
| **[Interpretable Machine Learning for Kronecker Coefficients](https://arxiv.org/abs/2502.11774)** | [Representation Theory](representation-theory.md), [Neural Network](neural-network.md), [Symbolic Regression](symbolic-regression.md), [PCA](pca.md), [Transformer](transformer.md) | arXiv 2025 |  |
| **[Learning Euler factors of elliptic curves](https://arxiv.org/abs/2502.10357)** | [Number Theory](number-theory.md), [Transformer](transformer.md) | arXiv 2025 |  |
| **[Learning to compute Gröbner Basis](https://proceedings.neurips.cc/paper_files/paper/2024/hash/3a1de90699eec7d7f42c91d81f94af16-Abstract-Conference.html)** | [Algebraic Geometry](./subjects/algebraic-geometry.md), [Transformer](./subjects/transformer.md) | NeurIPS 2024 | [Code](https://github.com/HiroshiKERA/transformer-groebner) |
| **[PatternBoost: Constructions in Mathematics with a Little Help from AI](https://arxiv.org/abs/2411.00566)** | [Discrete Geometry](discrete-geometry.md), [Combinatorics](combinatorics.md), [Transformer](transformer.md), [RL](rl.md) | arXiv 2024 | [Code](https://github.com/zawagner22/transformers_math_experiments) |
| **[Studying number theory with deep learning: a case study with the Möbius and squarefree indicator functions](https://arxiv.org/abs/2502.10335)** | [Number Theory](number-theory.md), [Transformer](transformer.md) | arXiv 2025 | [Code](https://github.com/davidlowryduda/mobius_case_study) |
| **[What makes math problems hard for reinforcement learning: a case study](https://arxiv.org/abs/2408.15332)** | [Group Theory](group-theory.md), [RL](rl.md), [Transformer](transformer.md) | arXiv 2024 | [Code](https://github.com/shehper/AC-Solver) |